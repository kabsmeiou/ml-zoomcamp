{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829c1e58-16bb-4972-8487-320acf1334c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3909e9cd-1e46-49b2-8a39-2be422c838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f85f5dd-9dd7-4481-8e72-deec9f8f95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26be0124-9043-4756-a417-63511e36a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "img = load_img('pants.jpg', target_size=(299, 299))\n",
    "\n",
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02c6d0d-7761-47ee-8331-618e37e8f022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8528e30e-1078-4690-bdb9-6deed7042678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c1f0764-b58f-4738-a49d-3be5763586af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8798642, -4.756312 , -2.3595333, -1.0892643,  9.903785 ,\n",
       "        -2.8261814, -3.6483104,  3.2411559, -2.6120963, -4.852037 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01638444-4239-420d-b525-e1c3f430657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2de9ecc6-22a5-4d1f-908c-27496c831b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8798642,\n",
       " 'hat': -4.756312,\n",
       " 'longsleeve': -2.3595333,\n",
       " 'outwear': -1.0892643,\n",
       " 'pants': 9.903785,\n",
       " 'shirt': -2.8261814,\n",
       " 'shoes': -3.6483104,\n",
       " 'shorts': 3.2411559,\n",
       " 'skirt': -2.6120963,\n",
       " 't-shirt': -4.852037}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f628d9-4604-4557-8e6d-6c746922271e",
   "metadata": {},
   "source": [
    "## Convert keras to tf-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1b296a1-fb2d-4d8d-9fe2-22a2fbc56d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 20:11:30.019626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,100]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-12-12 20:11:31.569893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,100]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqvrv9h8d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqvrv9h8d/assets\n",
      "2024-12-12 20:11:39.769799: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-12-12 20:11:39.769822: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-12-12 20:11:39.769974: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqvrv9h8d\n",
      "2024-12-12 20:11:39.788914: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-12-12 20:11:39.788937: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpqvrv9h8d\n",
      "2024-12-12 20:11:39.862644: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-12-12 20:11:40.141675: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqvrv9h8d\n",
      "2024-12-12 20:11:40.219591: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 449617 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "add5f2ac-6fb3-4cc5-b45e-6e78f0954607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 163M\n",
      "-rw-rw-r-- 1 kabs kabs  83M Dec  7  2021 clothing-model.h5\n",
      "-rw-rw-r-- 1 kabs kabs  81M Dec 12 20:11 clothing-model.tflite\n",
      "-rw-rw-r-- 1 kabs kabs  23K Dec 12 20:01 pants.jpg\n",
      "-rw-rw-r-- 1 kabs kabs 7.9K Dec 12 20:11 Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adc55277-0dc0-4d8d-8ad5-24d12fd9c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c091731-e113-456c-89b3-cd6a7d86782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_8:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 299, 299,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 299, 299,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# check details for input\n",
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e489964a-7202-42c3-8fa7-2f4a9d880fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8798664, -4.7563086, -2.3595314, -1.0892626,  9.903785 ,\n",
       "        -2.826182 , -3.648309 ,  3.2411585, -2.612095 , -4.852035 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "# initialize input\n",
    "interpreter.set_tensor(input_index, X)\n",
    "\n",
    "# invoke the interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# fetch output\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ad6b905-dced-44bd-90f4-62096f5a1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(zip(classes, preds[0])) # similar output as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a035cb8c-65a0-4362-8f98-07c9a104a8e8",
   "metadata": {},
   "source": [
    "## Removing tf dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5494e026-f2a9-43ca-8f00-824c2b53a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18818dd2-6498-4217-987e-3a4c6609e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open('pants.jpg') as img:\n",
    "    img = img.resize((299, 299), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "039823fa-9b6a-4bf7-ac54-030ebcaabb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_lite(inp):\n",
    "    inp /= 127.5\n",
    "    inp -= 1.\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e32e5ad6-6954-46c4-a8a3-8bf601ec62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input_lite(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4da71577-b9da-460b-9bf6-ce63dc4ced3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize input\n",
    "interpreter.set_tensor(input_index, X)\n",
    "\n",
    "# invoke the interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# fetch output\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds\n",
    "\n",
    "b = dict(zip(classes, preds[0])) # should be similar output as before\n",
    "assert a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efe086-62d7-48d1-9438-59b9cc7facf3",
   "metadata": {},
   "source": [
    "### Another way to remove tf dependency with processing input using keras-image-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2266eb76-abb1-4467-a5e3-b7d8837d4f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8798664,\n",
       " 'hat': -4.7563086,\n",
       " 'longsleeve': -2.3595314,\n",
       " 'outwear': -1.0892626,\n",
       " 'pants': 9.903785,\n",
       " 'shirt': -2.826182,\n",
       " 'shoes': -3.648309,\n",
       " 'shorts': 3.2411585,\n",
       " 'skirt': -2.612095,\n",
       " 't-shirt': -4.852035}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at this point, ive install tflite_runtime and keras-image-helper\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "# check details for input\n",
    "interpreter.get_input_details()\n",
    "\n",
    "# preprocessor\n",
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))\n",
    "\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)\n",
    "\n",
    "# initialize input\n",
    "interpreter.set_tensor(input_index, X)\n",
    "\n",
    "# invoke the interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# fetch output\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds\n",
    "\n",
    "dict(zip(classes, preds[0])) # should be similar output as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b907af-b4c8-4f29-8d87-e89b9ff00167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
