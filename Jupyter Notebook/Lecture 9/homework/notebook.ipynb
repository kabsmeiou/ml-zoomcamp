{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 17:08:24.228524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734080904.240569   16614 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734080904.244015   16614 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 17:08:24.257125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1ngoxmj6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1ngoxmj6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp1ngoxmj6'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  125009495370816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125009495663792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125009495798032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125009495796800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125009495790816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125009456074944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734080915.678970   16614 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1734080915.678981   16614 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-13 17:08:35.679117: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp1ngoxmj6\n",
      "2024-12-13 17:08:35.679380: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-13 17:08:35.679390: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp1ngoxmj6\n",
      "2024-12-13 17:08:35.681879: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-13 17:08:35.750503: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp1ngoxmj6\n",
      "2024-12-13 17:08:35.756000: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 76884 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# load original model\n",
    "model = keras.models.load_model('model_2024_hairstyle.keras')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('hairstyle-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 230M\n",
      "-rw-rw-r-- 1 kabs kabs  77M Dec 13 17:08 hairstyle-model.tflite\n",
      "-rw-rw-r-- 1 kabs kabs 154M Dec 13 16:38 model_2024_hairstyle.keras\n",
      "-rw-rw-r-- 1 kabs kabs 5.6K Dec 13 17:01 notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://google-coral.github.io/py-repo/\n",
      "Collecting tflite_runtime\n",
      "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/kabs/miniconda3/envs/tf-hw/lib/python3.10/site-packages (from tflite_runtime) (1.26.4)\n",
      "Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: tflite_runtime\n",
      "Successfully installed tflite_runtime-2.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# tflite_runtime and keras-image-helper\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='hairstyle-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg')\n",
    "\n",
    "prepared_img = prepare_image(image, target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23921569"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_input(x):\n",
    "    return x / 255.0\n",
    "\n",
    "x = np.array(prepared_img, dtype='float32')\n",
    "X = np.array([x])\n",
    "\n",
    "X = prepare_input(X)\n",
    "\n",
    "X[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize input\n",
    "interpreter.set_tensor(input_index, X)\n",
    "\n",
    "# invoke the interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# fetch output\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89377415]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
